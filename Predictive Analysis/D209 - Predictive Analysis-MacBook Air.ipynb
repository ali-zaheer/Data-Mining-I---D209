{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab76334b",
   "metadata": {},
   "source": [
    "#### D209 - Predictive Analysis\n",
    "azaheer@wgu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4cfe1",
   "metadata": {},
   "source": [
    "### Part I: Research Question\n",
    "#### A.  Describe the purpose of this data mining report by doing the following:\n",
    "1.  Propose one question relevant to a real-world organizational situation that you will answer using one of the following prediction methods:\n",
    "    - random forests\n",
    "    \n",
    "    A. I will use the random forests and the following predictors to identify which customer are at high risk of churn?\n",
    "        • Children\n",
    "        • Income\n",
    "        • Tenure\n",
    "        • Bandwidth_GB_Year\n",
    "        • Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694192ab",
   "metadata": {},
   "source": [
    "2.  Define one goal of the data analysis. Ensure that your goal is reasonable within the scope of the scenario and is represented in the available data.\n",
    "\n",
    "    A. The stakeholders can review the data provided by the analysis and create incentives to keep the customers that are likely to terminate their contracts with the company. This will lead to a lower churn rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47786166",
   "metadata": {},
   "source": [
    "### Part II: Method Justification\n",
    "#### B.  Explain the reasons for your chosen prediction method from part A1 by doing the following:\n",
    "1.  Explain how the prediction method you chose analyzes the selected data set. Include expected outcomes.\n",
    "\n",
    "    A. The 'random forest' algorithm improves accuracy by extending on 'single decision tree' where 'multiple decision trees’ are built with random subsets of the data. This extension ensures randomness and grows the decision tree forest. Additionally, it searches for the best feature among the random forest as opposed to the most important. This ensures there is a wide diversity which leads to a better model. It is one of the most accurate learning algorithms available (Richmond, 2016). I expect the outcome will improve accuracy and decrease overfitting.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a00764",
   "metadata": {},
   "source": [
    "2.  Summarize one assumption of the chosen prediction method.\n",
    "\n",
    "    A. I am assuming that the random forests has no formal distributional assumption and is non-parametric. It is able to  handle skewed, multi-modal data and categorical data that are ordinal or non ordinal (Richmond, 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043166f",
   "metadata": {},
   "source": [
    "3.  List the packages or libraries you have chosen for Python or R, and justify how each item on the list supports the analysis.\n",
    "\n",
    "     A. I will utilize Python due to my previous interaction with it and its Pandas and Sklearn modules. Additionally, I will be using Jupyter notebook as the IDE because it provides a user-friendly experience. Pandas is an excellent package for working with data set as it makes it easy to load and manipulate columns and/or rows to replace null values. I will use the ‘train_test_split’ module to split the data between training and test using the ‘test_size’ with ‘.20’ parameter to split it 80/20 and ‘random_state’with ‘21’ for shuffling before splitting. Then RandomForestRegressor will be used to instantiate the regression algorithms. ‘mean_squared_error’ and ‘accuracy_score’ are used to produce the error score and provide accuracy of the model respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee9163",
   "metadata": {},
   "source": [
    "### Part III: Data Preparation\n",
    "### C.  Perform data preparation for the chosen data set by doing the following:\n",
    "1.  Describe one data preprocessing goal relevant to the prediction method from part A1.\n",
    "\n",
    "    A. Select the appropriate independent variables and hyper-parameters for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f3d26",
   "metadata": {},
   "source": [
    "2.  Identify the initial data set variables that you will use to perform the analysis for the prediction question from part A1, and group each variable as continuous or categorical.\n",
    "    \n",
    "    A. I will be using the following independent variables to analyze and predict the future bandwidth usage:\n",
    "\n",
    "     ##### Categorical Predictor:\n",
    "     • Churn\n",
    "    \n",
    "     ##### Continuous Predictor:    \n",
    "     • Children\n",
    "     • Income\n",
    "     • Tenure\n",
    "     • Bandwidth_GB_Year\n",
    "     • Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c7863",
   "metadata": {},
   "source": [
    "3.  Explain the steps used to prepare the data for the analysis. Identify the code segment for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8226235",
   "metadata": {},
   "source": [
    "    1. Use Pandas to import the CSV file in the data frame.\n",
    "    2. Examine and ensure data type consistency in the columns.\n",
    "    3. Identify and resolve spelling mistakes in column headers or row level data.\n",
    "    4. Validate there are no Null value if so remove them.\n",
    "    5. Run regression on the prepared data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5da1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Show all Columns and Rows\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# Load data set\n",
    "df = pd.read_csv('churn_clean.csv')\n",
    "\n",
    "# Amend columns with no names\n",
    "df = df.rename(columns=({ 'Item1': 'Timely_Response', 'Item2':'Timely_Fixes', 'Item3':'Timely_Replacements', \n",
    "                         'Item4':'Reliability', 'Item5':'Options', 'Item6':'Respectful_Response',\n",
    "                         'Item7':'Courteous_Exchange', 'Item8':'Evidence_of_active_listening'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f37cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that I think are not relavant to the analysis\n",
    "df = df.drop(columns= [\"CaseOrder\", \"Customer_id\", \"Interaction\",\"Outage_sec_perweek\", \"UID\", \"City\", \"State\", \n",
    "                            \"Techie\",\"PaperlessBilling\",\"Yearly_equip_failure\",\"County\", \"Zip\", \"Lat\", \"Lng\", \"Population\", \n",
    "                            \"Area\", \"TimeZone\", \"Job\", \"PaymentMethod\", \"DeviceProtection\",\n",
    "                            \"OnlineBackup\",\"OnlineBackup\",\"OnlineBackup\", \"OnlineBackup\",\"Port_modem\",\"OnlineSecurity\", \n",
    "                            \"Multiple\",\"Phone\",\"TechSupport\",\"Contract\",\"Tablet\",\"InternetService\", \"StreamingTV\", \"StreamingMovies\", \n",
    "                            \"Timely_Response\", \"Timely_Fixes\", \"Timely_Replacements\",\"Reliability\",\"Options\",\"Gender\",\n",
    "                            \"Marital\",\"Respectful_Response\",\"Courteous_Exchange\",\"Evidence_of_active_listening\",\"Email\", \"Contacts\"\n",
    "                           ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffecf592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <th>Bandwidth_GB_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>28561.99</td>\n",
       "      <td>No</td>\n",
       "      <td>6.795513</td>\n",
       "      <td>172.455519</td>\n",
       "      <td>904.536110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>21704.77</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.156681</td>\n",
       "      <td>242.632554</td>\n",
       "      <td>800.982766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>9609.57</td>\n",
       "      <td>No</td>\n",
       "      <td>15.754144</td>\n",
       "      <td>159.947583</td>\n",
       "      <td>2054.706961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Children  Age    Income Churn     Tenure  MonthlyCharge  Bandwidth_GB_Year\n",
       "0         0   68  28561.99    No   6.795513     172.455519         904.536110\n",
       "1         1   27  21704.77   Yes   1.156681     242.632554         800.982766\n",
       "2         4   50   9609.57    No  15.754144     159.947583        2054.706961"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display data set with all the columns\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446d791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Children             0\n",
       "Age                  0\n",
       "Income               0\n",
       "Churn                0\n",
       "Tenure               0\n",
       "MonthlyCharge        0\n",
       "Bandwidth_GB_Year    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate there are no nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4088b2",
   "metadata": {},
   "source": [
    "4. Provide a copy of the prepared data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e8d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepared dataset in the root folder 'prepared_dataset.csv'\n",
    "df.to_csv('prepared_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbd1db",
   "metadata": {},
   "source": [
    "### Part IV: Analysis\n",
    "#### D.  Perform the data analysis and report on the results by doing the following:\n",
    "1.  Split the data into training and test data sets and provide the file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7225f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data conversion\n",
    "df['Churn'] = [1 if v == 'Yes' else 0 for v in df['Churn']]\n",
    "\n",
    "# Feature Selection\n",
    "X = df.drop('Churn', axis=1).values\n",
    "y = df['Churn']\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.02, random_state=21)\n",
    "\n",
    "# Save training and test data set to csv file\n",
    "pd.DataFrame(X_train).to_csv('X_train.csv')\n",
    "pd.DataFrame(X_test).to_csv('X_test.csv')\n",
    "pd.DataFrame(y_train).to_csv('y_train.csv')\n",
    "pd.DataFrame(y_test).to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "314a57f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <th>Bandwidth_GB_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>28561.99</td>\n",
       "      <td>0</td>\n",
       "      <td>6.795513</td>\n",
       "      <td>172.455519</td>\n",
       "      <td>904.536110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>21704.77</td>\n",
       "      <td>1</td>\n",
       "      <td>1.156681</td>\n",
       "      <td>242.632554</td>\n",
       "      <td>800.982766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>9609.57</td>\n",
       "      <td>0</td>\n",
       "      <td>15.754144</td>\n",
       "      <td>159.947583</td>\n",
       "      <td>2054.706961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>18925.23</td>\n",
       "      <td>0</td>\n",
       "      <td>17.087227</td>\n",
       "      <td>119.956840</td>\n",
       "      <td>2164.579412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>40074.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.670972</td>\n",
       "      <td>149.948316</td>\n",
       "      <td>271.493436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Children  Age    Income  Churn     Tenure  MonthlyCharge  Bandwidth_GB_Year\n",
       "0         0   68  28561.99      0   6.795513     172.455519         904.536110\n",
       "1         1   27  21704.77      1   1.156681     242.632554         800.982766\n",
       "2         4   50   9609.57      0  15.754144     159.947583        2054.706961\n",
       "3         1   48  18925.23      0  17.087227     119.956840        2164.579412\n",
       "4         0   83  40074.19      1   1.670972     149.948316         271.493436"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de6bfe",
   "metadata": {},
   "source": [
    "2.  Describe the analysis technique you used to appropriately analyze the data. Include screenshots of the intermediate calculations you performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887332af",
   "metadata": {},
   "source": [
    "I used the Random Forest algorithm to build several decision trees and then merge them to get an accurate and stable prediction. The algorithm grows the model and adds randomness by searching for the best feature while splitting a node. This will result in diversity that leads to a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23b565",
   "metadata": {},
   "source": [
    "The below example shows the algorithm flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d319ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"two-tree-random-forest.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"two-tree-random-forest.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2be5e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "rdf = RandomForestRegressor(n_estimators=1000, random_state=1)\n",
    "rdf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04605d0",
   "metadata": {},
   "source": [
    "3.  Provide the code used to perform the prediction analysis from part D2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c473c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Train\n",
    "y_pred_train = rdf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c8b38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Test\n",
    "y_pred_test = rdf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e170c6",
   "metadata": {},
   "source": [
    "### Part V: Data Summary and Implications\n",
    "#### E.  Summarize your data analysis by doing the following:\n",
    "1.  Explain the accuracy and the mean squared error (MSE) of your prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8834507d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.14\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "print('MSE: {0:.2f}'.format(mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed9ecb5",
   "metadata": {},
   "source": [
    "2.  Discuss the results and implications of your prediction analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c57311",
   "metadata": {},
   "source": [
    "The churn variable has a low MSE score of .14, suggesting a high accuracy rate at predicting which customer will churn based on the dataset. However, since Mean Square Error is a square of averages, a single high value will lead to a higher mean. This makes MSE vulnerable to large outliers.\n",
    "\n",
    "The model adequately predicts the Churn rate but could perform better if further analysis is performed on the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dfffa",
   "metadata": {},
   "source": [
    "3.  Discuss one limitation of your data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4e058",
   "metadata": {},
   "source": [
    "There are a couple of limitations:\n",
    "    \n",
    "    1. The algorithm requires more trees to have an accurate prediction, which results in a slower model.\n",
    "    2. It doesn't predict beyond the range in the training data, which can lead to overfitting in a noisy dataset. Thompson, B. (2021, December 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632d8b1f",
   "metadata": {},
   "source": [
    "4.  Recommend a course of action for the real-world organizational situation from part A1 based on your results and implications discussed in part E2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5e137",
   "metadata": {},
   "source": [
    "The stakeholders need to analyse which features are common among the customers that have left the company in the past. This will help them identify which customers are at higher risk of churn and provide those customers with additional relevant services at a competitive price. This will show the customers that the company is a one-stop shop for all their needs, which will lead them to stay with the company for a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857b0ae",
   "metadata": {},
   "source": [
    "### Part VI: Demonstration\n",
    "#### F.  Provide a Panopto video recording that includes a demonstration of the functionality of the code used for the analysis and a summary of the programming environment.\n",
    " \n",
    "Note: The audiovisual recording should feature you visibly presenting the material (i.e., not in voiceover or embedded video) and should simultaneously capture both you and your multimedia presentation.\n",
    " \n",
    "Note: For instructions on how to access and use Panopto, use the \"Panopto How-To Videos\" web link provided below. To access Panopto's website, navigate to the web link titled \"Panopto Access,\" and then choose to log in using the “WGU” option. If prompted, log in using your WGU student portal credentials, and then it will forward you to Panopto’s website.\n",
    " \n",
    "To submit your recording, upload it to the Panopto drop box titled “Data Mining I – NVM2.” Once the recording has been uploaded and processed in Panopto's system, retrieve the URL of the recording from Panopto and copy and paste it into the Links option. Upload the remaining task requirements using the Attachments option.\n",
    " \n",
    "Panapto: https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=0d1c8144-b02f-44b4-a2f5-ae2c014ef5e3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5c7c1",
   "metadata": {},
   "source": [
    "#### G.  Record the web sources used to acquire data or segments of third-party code to support the analysis. Ensure the web sources are reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a834d",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    "Pandas. (2021). Pandas DataFrames. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html\n",
    "\n",
    "Get started with references. (2021). Jupyterbook. https://jupyterbook.org/tutorials/references.html#tutorials-references\n",
    "\n",
    "Marques, A. M. (2020, March 11). How to show all columns / rows of a Pandas Dataframe? Towards Data Science. https://towardsdatascience.com/how-to-show-all-columns-rows-of-a-pandas-dataframe-c49d4507fcf\n",
    "\n",
    "Starmer, J. (2018, March 5). StatQuest: Logistic Regression. YouTube. https://www.youtube.com/watch?v=yIYKR4sgzI8&t=121s\n",
    "\n",
    "V. (2019, July 21). Pandas: Apply a function to single or selected columns or rows in Dataframe. ThisPointer. https://thispointer.com/pandas-apply-a-function-to-single-or-selected-columns-or-rows-in-dataframe/\n",
    "\n",
    "Wijaya, C. Y. (2021, December 15). 5 Must-Know Dimensionality Reduction Techniques via Prince. Medium. https://towardsdatascience.com/5-must-know-dimensionality-reduction-techniques-via-prince-e6ffb27e55d1\n",
    "\n",
    "Thompson, B. (2021, December 13). A limitation of Random Forest Regression - Towards Data Science. Medium. https://towardsdatascience.com/a-limitation-of-random-forest-regression-db8ed7419e9f\n",
    "\n",
    "Great Learning Team. (2022, January 17). Mean Squared Error - Explained | What is Mean Square Error? GreatLearning Blog: Free Resources What Matters to Shape Your Career! https://www.mygreatlearning.com/blog/mean-square-error-explained/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067723b",
   "metadata": {},
   "source": [
    "#### H.  Acknowledge sources, using in-text citations and references, for content that is quoted, paraphrased, or summarized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62bcb8",
   "metadata": {},
   "source": [
    "```` \n",
    "Richmond, S. (2016, March 21). Algorithms Exposed: Random Forest | BCCVL. Bccvl.Org.Au. Retrieved 10 January 2022, from https://bccvl.org.au/algorithms-exposed-random-forest/\n",
    "\n",
    "Chantal D. Larose, & Daniel T. Larose. (2019). Data Science Using Python and R. Wiley.\n",
    "\n",
    "Donges, N. (2021, September 17). A Complete Guide to the Random Forest Algorithm. Built In. https://builtin.com/data-science/random-forest-algorithm\n",
    "\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
